{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling Necessary Libraries AND Getting Today's Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "from scipy.stats import poisson\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Get today's date\n",
    "given_date = \"2024-10-17\" #year-month-day\n",
    "threshold = 80 #threshold for percentages to highlight in final dataframe (between 1 and 100)\n",
    "\n",
    "wanted_leagues = ['argentina', 'austria', 'belgium',\n",
    "                  'brazil', 'denmark', 'portugal2',\n",
    "                  'england', 'england2', 'england3', 'england4', 'england5', 'france', 'france2',\n",
    "                  'germany', 'germany2', 'greece', 'italy', 'italy2',\n",
    "                   'mexico', 'netherlands', 'norway','poland', 'portugal',\n",
    "                  'scotland', 'spain', 'spain2', 'sweden',\n",
    "                  'switzerland', 'turkey', 'usa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Days between given date and today\n",
    "# Today's date\n",
    "today = datetime.now().date()\n",
    "\n",
    "# Specific date\n",
    "specific_date = datetime.strptime(given_date, \"%Y-%m-%d\").date()\n",
    "\n",
    "# Calculate the difference in days\n",
    "difference = specific_date - today\n",
    "\n",
    "# Add one day to the difference\n",
    "days_until_specific_date = difference.days + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Today's Matches and Leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.soccerstats.com/matches.asp?matchday=\" + str(days_until_specific_date) + \"&listing=2\"\n",
    "page = requests.get(URL)\n",
    "liqa = []\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(id=\"btable\")\n",
    "sth = results.find_all(\"tr\", attrs={'height': '34'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>league</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [league, home_team, away_team]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize lists to store extracted data\n",
    "league_list = []\n",
    "home_team_list = []\n",
    "away_team_list = []\n",
    "\n",
    "# Iterate through each <tr> element\n",
    "for tr_element in sth:\n",
    "    # Find the <td> element with sorttable_customkey attribute\n",
    "    td_element = tr_element.find('td', attrs={'sorttable_customkey': True})\n",
    "    \n",
    "    # Check if <td> element exists and contains an <img> element with the alt attribute\n",
    "    if td_element and td_element.find('img', alt=True):\n",
    "        # Extract league info\n",
    "        league = td_element['sorttable_customkey']\n",
    "        if league in wanted_leagues:\n",
    "            league_list.append(league)\n",
    "        \n",
    "        # Find <td> elements with class \"steam\"\n",
    "        td_elements_steam = tr_element.find_all('td', class_='steam')\n",
    "        \n",
    "        # Extract home and away team info\n",
    "        if len(td_elements_steam) == 2 and league in wanted_leagues:\n",
    "            home_team = td_elements_steam[0].get_text(strip=True)\n",
    "            away_team = td_elements_steam[1].get_text(strip=True)\n",
    "            home_team_list.append(home_team)\n",
    "            away_team_list.append(away_team)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Create DataFrame\n",
    "matches = pd.DataFrame({\n",
    "    'league': league_list,\n",
    "    'home_team': home_team_list,\n",
    "    'away_team': away_team_list\n",
    "})\n",
    "\n",
    "# Display DataFrame\n",
    "matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Date and Collecting Leagues for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "day_abbreviations = {0: \"Mo\", 1: \"Tu\", 2: \"We\", 3: \"Th\", 4: \"Fr\", 5: \"Sa\", 6: \"Su\"}\n",
    "given_date_parsed = parser.parse(given_date)\n",
    "\n",
    "# Manually format the day to remove leading zeros\n",
    "day = given_date_parsed.day\n",
    "month = given_date_parsed.strftime('%b')\n",
    "\n",
    "# Format the date as \"Su 1 Oct\" or \"Tu 10 Oct\" without leading zero for single-digit days\n",
    "formatted_date = f\"{day_abbreviations[given_date_parsed.weekday()]} {day} {month}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the Web for the League Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>League</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>FT</th>\n",
       "      <th>HT</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTTG</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTTG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr 10 May</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Sarmiento</td>\n",
       "      <td>Instituto</td>\n",
       "      <td>1 - 2</td>\n",
       "      <td>(0-1)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sa 11 May</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Argentinos Jrs</td>\n",
       "      <td>Rosario Central</td>\n",
       "      <td>3 - 2</td>\n",
       "      <td>(2-2)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sa 11 May</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Newells</td>\n",
       "      <td>Platense</td>\n",
       "      <td>2 - 0</td>\n",
       "      <td>(0-0)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sa 11 May</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Huracan</td>\n",
       "      <td>Defensa y J.</td>\n",
       "      <td>3 - 1</td>\n",
       "      <td>(1-0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sa 11 May</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Godoy Cruz</td>\n",
       "      <td>Barracas C.</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>(0-0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3396</th>\n",
       "      <td>Su 6 Oct</td>\n",
       "      <td>Usa</td>\n",
       "      <td>SJ Earthquakes</td>\n",
       "      <td>Real Salt Lake</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>(0-0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3397</th>\n",
       "      <td>Su 6 Oct</td>\n",
       "      <td>Usa</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Nashville SC</td>\n",
       "      <td>3 - 1</td>\n",
       "      <td>(3-0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>Mo 7 Oct</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>0 - 0</td>\n",
       "      <td>(0-0)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>Su 13 Oct</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Columbus Crew</td>\n",
       "      <td>New England</td>\n",
       "      <td>4 - 0</td>\n",
       "      <td>(2-0)</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>Mo 14 Oct</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Los Angeles FC</td>\n",
       "      <td>1 - 2</td>\n",
       "      <td>(0-1)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date     League            Home             Away     FT     HT  \\\n",
       "0     Fr 10 May  Argentina       Sarmiento        Instituto  1 - 2  (0-1)   \n",
       "1     Sa 11 May  Argentina  Argentinos Jrs  Rosario Central  3 - 2  (2-2)   \n",
       "2     Sa 11 May  Argentina         Newells         Platense  2 - 0  (0-0)   \n",
       "3     Sa 11 May  Argentina         Huracan     Defensa y J.  3 - 1  (1-0)   \n",
       "4     Sa 11 May  Argentina      Godoy Cruz      Barracas C.  0 - 1  (0-0)   \n",
       "3396   Su 6 Oct        Usa  SJ Earthquakes   Real Salt Lake  0 - 1  (0-0)   \n",
       "3397   Su 6 Oct        Usa   New York City     Nashville SC  3 - 1  (3-0)   \n",
       "3398   Mo 7 Oct        Usa        Portland           Dallas  0 - 0  (0-0)   \n",
       "3399  Su 13 Oct        Usa   Columbus Crew      New England  4 - 0  (2-0)   \n",
       "3400  Mo 14 Oct        Usa       Vancouver   Los Angeles FC  1 - 2  (0-1)   \n",
       "\n",
       "      FTHG  FTAG  FTTG  HTHG  HTAG  HTTG  \n",
       "0        1     2     3     0     1     1  \n",
       "1        3     2     5     2     2     4  \n",
       "2        2     0     2     0     0     0  \n",
       "3        3     1     4     1     0     1  \n",
       "4        0     1     1     0     0     0  \n",
       "3396     0     1     1     0     0     0  \n",
       "3397     3     1     4     3     0     3  \n",
       "3398     0     0     0     0     0     0  \n",
       "3399     4     0     4     2     0     2  \n",
       "3400     1     2     3     0     1     1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final =  pd.DataFrame()\n",
    "liqa = ''\n",
    "unique_leagues = wanted_leagues#matches['league'].unique().tolist()\n",
    "next_matches = pd.DataFrame()\n",
    "\n",
    "for i in unique_leagues:\n",
    "    URL = \"https://www.soccerstats.com/results.asp?league=\" + i + \"&pmtype=bydate\"\n",
    "    page = requests.get(URL)\n",
    "    liqa = i\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find(id=\"btable\")\n",
    "    sth = results.find_all(\"tr\", class_=\"odd\")\n",
    "    sth\n",
    "\n",
    "\n",
    "    date, league, home, away, ft, ht = [], [], [], [], [],[]\n",
    "    for i in sth:\n",
    "        date.append(i.find_all(\"td\", align = 'right')[0].get_text(strip=True))\n",
    "        league.append(liqa.capitalize())\n",
    "        home.append(i.find_all(\"td\", align = 'right')[1].get_text(strip=True))\n",
    "        away.append(i.find(\"td\", align = \"left\").get_text(strip = True))\n",
    "        ft.append(i.find_all(\"td\", align = 'center')[0].get_text(strip = True))\n",
    "        try:\n",
    "            ht.append(i.find_all(\"td\", align = 'center')[2].get_text(strip = True))\n",
    "        except IndexError as e:\n",
    "            ht.append('NA')#print(\"Last output before error occurred:\", i.find_all(\"td\", align = 'center'))\n",
    "\n",
    "    data = {'Date': date, 'League': league,'Home': home, 'Away': away, 'FT': ft, 'HT': ht}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "    next_df = df[(df['Date'] == formatted_date) & (df['HT'] == '')]\n",
    "    next_matches = pd.concat([next_matches, next_df], ignore_index = True)\n",
    "    df.replace('', pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "    df_cleaned = df.dropna()\n",
    "\n",
    "#For Half-Time Results\n",
    "    hthg, htag = [], []\n",
    "    for i in df_cleaned['HT']:\n",
    "        if i == 'NA':\n",
    "            hthg.append('NA')\n",
    "            htag.append('NA')\n",
    "        elif i == '+' or i == '-':\n",
    "            hthg.append('NA')\n",
    "            htag.append('NA')\n",
    "        else:\n",
    "            try:\n",
    "                hthg.append(int(i[1]))\n",
    "                htag.append(int(i[3]))\n",
    "            except IndexError as e:\n",
    "                print(\"Last output before error occurred:\", i)\n",
    "\n",
    "\n",
    "\n",
    "#For Full-Time Results\n",
    "    hg, ag, tg = [], [], []\n",
    "    for i in df_cleaned['FT']:\n",
    "        if len(i) < 5 or ':' in i:\n",
    "            hg.append('NA')\n",
    "            ag.append('NA')\n",
    "            tg.append('NA')\n",
    "        else:\n",
    "            try:\n",
    "                hghg = int(i.split(' - ')[0])\n",
    "                hg.append(hghg)\n",
    "                agag = int(i.split(' - ')[1])\n",
    "                ag.append(agag)\n",
    "                tg.append(hghg + agag)\n",
    "            except:\n",
    "                print(hghg + agag)\n",
    "\n",
    "    \n",
    "    df_cleaned['FTHG'], df_cleaned['FTAG'], df_cleaned['FTTG'] = hg, ag, tg\n",
    "    df_cleaned['HTHG'], df_cleaned['HTAG'] = hthg, htag\n",
    "    df_cleaned['HTTG'] = df_cleaned['HTHG'] + df_cleaned['HTAG']\n",
    "    \n",
    "    final = pd.concat([final, df_cleaned], ignore_index=True)\n",
    "    \n",
    "final = final[final['HT'] != 'NA']\n",
    "combined_df = pd.concat([final.head(), final.tail()])\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>League</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>FT</th>\n",
       "      <th>HT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Th 17 Oct</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Fortaleza</td>\n",
       "      <td>Atletico MG</td>\n",
       "      <td>01:45</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th 17 Oct</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>Vasco da Gama</td>\n",
       "      <td>01:45</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Th 17 Oct</td>\n",
       "      <td>England3</td>\n",
       "      <td>Shrewsbury</td>\n",
       "      <td>Exeter City</td>\n",
       "      <td>20:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Th 17 Oct</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Fortaleza</td>\n",
       "      <td>Atletico MG</td>\n",
       "      <td>01:45</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Th 17 Oct</td>\n",
       "      <td>Brazil</td>\n",
       "      <td>Sao Paulo</td>\n",
       "      <td>Vasco da Gama</td>\n",
       "      <td>01:45</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Th 17 Oct</td>\n",
       "      <td>England3</td>\n",
       "      <td>Shrewsbury</td>\n",
       "      <td>Exeter City</td>\n",
       "      <td>20:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date    League        Home           Away     FT HT\n",
       "0  Th 17 Oct    Brazil   Fortaleza    Atletico MG  01:45   \n",
       "1  Th 17 Oct    Brazil   Sao Paulo  Vasco da Gama  01:45   \n",
       "2  Th 17 Oct  England3  Shrewsbury    Exeter City  20:00   \n",
       "0  Th 17 Oct    Brazil   Fortaleza    Atletico MG  01:45   \n",
       "1  Th 17 Oct    Brazil   Sao Paulo  Vasco da Gama  01:45   \n",
       "2  Th 17 Oct  England3  Shrewsbury    Exeter City  20:00   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_leagues = next_matches['League'].unique().tolist()\n",
    "pd.concat([next_matches.head(), next_matches.tail()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Functions Needed for Dixon-Coles Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.stats import poisson\n",
    "\n",
    "def rho_correction(x, y, lambda_x, mu_y, rho):\n",
    "    if x==0 and y==0:\n",
    "        return 1- (lambda_x * mu_y * rho)\n",
    "    elif x==0 and y==1:\n",
    "        return 1 + (lambda_x * rho)\n",
    "    elif x==1 and y==0:\n",
    "        return 1 + (mu_y * rho)\n",
    "    elif x==1 and y==1:\n",
    "        return 1 - rho\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "def dc_log_like(x, y, alpha_x, beta_x, alpha_y, beta_y, rho, gamma):\n",
    "    lambda_x, mu_y = np.exp(alpha_x + beta_y + gamma), np.exp(alpha_y + beta_x) \n",
    "    return (np.log(rho_correction(x, y, lambda_x, mu_y, rho)) + \n",
    "            np.log(poisson.pmf(x, lambda_x)) + np.log(poisson.pmf(y, mu_y)))\n",
    "\n",
    "\n",
    "\n",
    "def solve_parameters(dataset, half_or_full = 'full', debug = False, init_vals=None, options={'disp': True, 'maxiter':100},\n",
    "                     constraints = [{'type':'eq', 'fun': lambda x: sum(x[:20])-20}] , **kwargs):\n",
    "    teams = np.sort(dataset['Home'].unique())\n",
    "    # check for no weirdness in dataset\n",
    "    away_teams = np.sort(dataset['Away'].unique())\n",
    "    if not np.array_equal(teams, away_teams):\n",
    "        raise ValueError(\"Something's not right\")\n",
    "    n_teams = len(teams)\n",
    "    if init_vals is None:\n",
    "        # random initialisation of model parameters\n",
    "        init_vals = np.concatenate((np.random.uniform(0,1,(n_teams)), # attack strength\n",
    "                                      np.random.uniform(0,-1,(n_teams)), # defence strength\n",
    "                                      np.array([0, 1.0]) # rho (score correction), gamma (home advantage)\n",
    "                                     ))\n",
    "\n",
    "    def estimate_paramters(params):\n",
    "        score_coefs = dict(zip(teams, params[:n_teams]))\n",
    "        defend_coefs = dict(zip(teams, params[n_teams:(2*n_teams)]))\n",
    "        rho, gamma = params[-2:]\n",
    "        if half_or_full == 'full':\n",
    "            log_like = [dc_log_like(row.FTHG, row.FTAG, score_coefs[row.Home], defend_coefs[row.Home],\n",
    "                        score_coefs[row.Away], defend_coefs[row.Away], rho, gamma) for row in dataset.itertuples()]\n",
    "        elif half_or_full == 'half':\n",
    "            log_like = [dc_log_like(row.HTHG, row.HTAG, score_coefs[row.Home], defend_coefs[row.Home],\n",
    "                        score_coefs[row.Away], defend_coefs[row.Away], rho, gamma) for row in dataset.itertuples()]\n",
    "\n",
    "        return -sum(log_like)\n",
    "    opt_output = minimize(estimate_paramters, init_vals, options=options, constraints = constraints, **kwargs)\n",
    "    if debug:\n",
    "        # sort of hacky way to investigate the output of the optimisation process\n",
    "        return opt_output\n",
    "    else:\n",
    "        return dict(zip([\"attack_\"+team for team in teams] + \n",
    "                        [\"defence_\"+team for team in teams] +\n",
    "                        ['rho', 'home_adv'],\n",
    "                        opt_output.x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Lambda Values for Dixon-Coles Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 747.2820128238931\n",
      "            Iterations: 57\n",
      "            Function evaluations: 2529\n",
      "            Gradient evaluations: 57\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 512.7176326646152\n",
      "            Iterations: 41\n",
      "            Function evaluations: 1808\n",
      "            Gradient evaluations: 41\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 311.8189841337434\n",
      "            Iterations: 75\n",
      "            Function evaluations: 3913\n",
      "            Gradient evaluations: 75\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 207.36491841839967\n",
      "            Iterations: 71\n",
      "            Function evaluations: 3757\n",
      "            Gradient evaluations: 71\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "stats_df = pd.DataFrame()\n",
    "full_time_models = []\n",
    "half_time_models = []\n",
    "\n",
    "for league in next_leagues:\n",
    "    league_df = final[final['League'] == league.capitalize()]\n",
    "    \n",
    "    full_time_estimates = solve_parameters(league_df, half_or_full = 'full')\n",
    "    full_time_models.append(full_time_estimates)\n",
    "\n",
    "    half_time_estimates = solve_parameters(league_df, half_or_full = 'half')\n",
    "    half_time_models.append(half_time_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attack_Barnsley': 1.162626799507997,\n",
       " 'attack_Birmingham City': 1.528910570846106,\n",
       " 'attack_Blackpool': 1.3553002361235627,\n",
       " 'attack_Bolton': 1.3398134579721848,\n",
       " 'attack_Bristol Rovers': 0.9752231499133093,\n",
       " 'attack_Burton Albion': 0.8541119560801218,\n",
       " 'attack_Cambridge Utd': 0.37080222937196683,\n",
       " 'attack_Charlton': 0.7540414045207695,\n",
       " 'attack_Crawley Town': 0.4692197886275156,\n",
       " 'attack_Exeter City': 0.7950561327959192,\n",
       " 'attack_Huddersfield': 0.9482107755023386,\n",
       " 'attack_Leyton Orient': 0.8417655307477245,\n",
       " 'attack_Lincoln City': 1.2088639642167456,\n",
       " 'attack_Mansfield': 1.2014514155492253,\n",
       " 'attack_Northampton': 0.9292323961020611,\n",
       " 'attack_Peterborough': 1.5640422135614724,\n",
       " 'attack_Reading': 1.2650707404223887,\n",
       " 'attack_Rotherham': 0.7833534962864709,\n",
       " 'attack_Shrewsbury': 1.010685238131908,\n",
       " 'attack_Stevenage': 0.6422176258298231,\n",
       " 'attack_Stockport': 1.0245016976594619,\n",
       " 'attack_Wigan Athletic': 0.7786945338096266,\n",
       " 'attack_Wrexham': 1.2254909458696053,\n",
       " 'attack_Wycombe': 1.293754827002317,\n",
       " 'defence_Barnsley': -0.6321626917438734,\n",
       " 'defence_Birmingham City': -1.1446548562645285,\n",
       " 'defence_Blackpool': -0.5172945256262643,\n",
       " 'defence_Bolton': -0.46791546581969434,\n",
       " 'defence_Bristol Rovers': -0.6020820496416327,\n",
       " 'defence_Burton Albion': -0.39603618319850625,\n",
       " 'defence_Cambridge Utd': -0.4811892390443735,\n",
       " 'defence_Charlton': -1.2820538379198454,\n",
       " 'defence_Crawley Town': -0.5728029635660428,\n",
       " 'defence_Exeter City': -1.515750709466243,\n",
       " 'defence_Huddersfield': -1.1806448646700494,\n",
       " 'defence_Leyton Orient': -0.9279596885485522,\n",
       " 'defence_Lincoln City': -1.2266272825375077,\n",
       " 'defence_Mansfield': -0.8310234374717398,\n",
       " 'defence_Northampton': -0.5144791515532618,\n",
       " 'defence_Peterborough': -0.4196311224300539,\n",
       " 'defence_Reading': -0.6704728728314566,\n",
       " 'defence_Rotherham': -0.9093485057981717,\n",
       " 'defence_Shrewsbury': -0.49931512908019116,\n",
       " 'defence_Stevenage': -1.4899588944037565,\n",
       " 'defence_Stockport': -1.2791824167092076,\n",
       " 'defence_Wigan Athletic': -1.8370380666309416,\n",
       " 'defence_Wrexham': -1.4152062634474196,\n",
       " 'defence_Wycombe': -0.7541082821083284,\n",
       " 'rho': -0.06976841477102103,\n",
       " 'home_adv': 0.12017869372498775}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_time_models[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Probability Matrices for Half/Full Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.91560001e-02, 4.98504320e-02, 2.61755334e-02, 8.49446203e-03,\n",
       "        2.06746175e-03, 4.02558566e-04, 6.53189833e-05, 9.08454061e-06,\n",
       "        1.10554030e-06],\n",
       "       [1.02270929e-01, 1.07307961e-01, 5.03258305e-02, 1.63316961e-02,\n",
       "        3.97496119e-03, 7.73970634e-04, 1.25584149e-04, 1.74661981e-05,\n",
       "        2.12554346e-06],\n",
       "       [1.02085291e-01, 9.93858981e-02, 4.83789419e-02, 1.56998934e-02,\n",
       "        3.82118714e-03, 7.44029059e-04, 1.20725842e-04, 1.67905065e-05,\n",
       "        2.04331538e-06],\n",
       "       [6.54240354e-02, 6.36940585e-02, 3.10049133e-02, 1.00616883e-02,\n",
       "        2.44890796e-03, 4.76830529e-04, 7.73703208e-05, 1.07606363e-05,\n",
       "        1.30951223e-06],\n",
       "       [3.14465313e-02, 3.06150055e-02, 1.49027337e-02, 4.83622257e-03,\n",
       "        1.17708516e-03, 2.29192010e-04, 3.71885989e-05, 5.17217691e-06,\n",
       "        6.29426435e-07],\n",
       "       [1.20920004e-02, 1.17722574e-02, 5.73048456e-03, 1.85965202e-03,\n",
       "        4.52619530e-04, 8.81302250e-05, 1.42999732e-05, 1.98883511e-06,\n",
       "        2.42030660e-07],\n",
       "       [3.87473775e-03, 3.77227989e-03, 1.83626563e-03, 5.95903376e-04,\n",
       "        1.45036546e-04, 2.82402826e-05, 4.58225636e-06, 6.37298560e-07,\n",
       "        7.75558469e-08],\n",
       "       [1.06424026e-03, 1.03609906e-03, 5.04350989e-04, 1.63671558e-04,\n",
       "        3.98359171e-05, 7.75651094e-06, 1.25856820e-06, 1.75041210e-07,\n",
       "        2.13015848e-08],\n",
       "       [2.55767352e-04, 2.49004217e-04, 1.21209958e-04, 3.93349534e-05,\n",
       "        9.57370945e-06, 1.86411127e-06, 3.02469910e-07, 4.20674058e-08,\n",
       "        5.11937966e-09]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First Function needs work to make it more understandable and a df rather than matrix!\n",
    "def dixon_coles_simulate_match(params_dict, homeTeam, awayTeam, max_goals=10):\n",
    "    team_avgs = [np.exp(params_dict['attack_'+homeTeam] + params_dict['defence_'+awayTeam] + params_dict['home_adv']),\n",
    "                 np.exp(params_dict['defence_'+homeTeam] + params_dict['attack_'+awayTeam])]\n",
    "    team_pred = [[poisson.pmf(i, team_avg) for i in range(0, max_goals+1)] for team_avg in team_avgs]\n",
    "    output_matrix = np.outer(np.array(team_pred[0]), np.array(team_pred[1]))\n",
    "    correction_matrix = np.array([[rho_correction(home_goals, away_goals, team_avgs[0],\n",
    "                                                   team_avgs[1], params_dict['rho']) for away_goals in range(2)]\n",
    "                                   for home_goals in range(2)])\n",
    "    output_matrix[:2,:2] = output_matrix[:2,:2] * correction_matrix\n",
    "    return output_matrix\n",
    "\n",
    "full_time_matrices = []\n",
    "half_time_matrices = []\n",
    "\n",
    "for i in range(len(next_matches)):\n",
    "    my_league = next_matches['League'].iloc[i]\n",
    "    league_index = next_leagues.index(my_league)\n",
    "    ft_match_score_matrix = dixon_coles_simulate_match(full_time_models[league_index], \n",
    "                                                       next_matches['Home'].iloc[i], next_matches['Away'].iloc[i], max_goals = 8)\n",
    "    ht_match_score_matrix = dixon_coles_simulate_match(half_time_models[league_index], \n",
    "                                                       next_matches['Home'].iloc[i], next_matches['Away'].iloc[i], max_goals = 4)\n",
    "    full_time_matrices.append(ft_match_score_matrix)\n",
    "    half_time_matrices.append(ht_match_score_matrix)\n",
    "\n",
    "full_time_matrices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Probabilities of Dixon-Coles Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_cbc44_row0_col7, #T_cbc44_row0_col13, #T_cbc44_row0_col19, #T_cbc44_row0_col24, #T_cbc44_row0_col29, #T_cbc44_row1_col7, #T_cbc44_row1_col13, #T_cbc44_row1_col19, #T_cbc44_row1_col24, #T_cbc44_row1_col29, #T_cbc44_row2_col9, #T_cbc44_row2_col12, #T_cbc44_row2_col13, #T_cbc44_row2_col21, #T_cbc44_row2_col28, #T_cbc44_row2_col29 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_cbc44\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_cbc44_level0_col0\" class=\"col_heading level0 col0\" >League</th>\n",
       "      <th id=\"T_cbc44_level0_col1\" class=\"col_heading level0 col1\" >Home</th>\n",
       "      <th id=\"T_cbc44_level0_col2\" class=\"col_heading level0 col2\" >Away</th>\n",
       "      <th id=\"T_cbc44_level0_col3\" class=\"col_heading level0 col3\" >FT1</th>\n",
       "      <th id=\"T_cbc44_level0_col4\" class=\"col_heading level0 col4\" >FTX</th>\n",
       "      <th id=\"T_cbc44_level0_col5\" class=\"col_heading level0 col5\" >FT2</th>\n",
       "      <th id=\"T_cbc44_level0_col6\" class=\"col_heading level0 col6\" >FTR</th>\n",
       "      <th id=\"T_cbc44_level0_col7\" class=\"col_heading level0 col7\" >DC1X</th>\n",
       "      <th id=\"T_cbc44_level0_col8\" class=\"col_heading level0 col8\" >DC12</th>\n",
       "      <th id=\"T_cbc44_level0_col9\" class=\"col_heading level0 col9\" >DCX2</th>\n",
       "      <th id=\"T_cbc44_level0_col10\" class=\"col_heading level0 col10\" >1.5O</th>\n",
       "      <th id=\"T_cbc44_level0_col11\" class=\"col_heading level0 col11\" >2.5O</th>\n",
       "      <th id=\"T_cbc44_level0_col12\" class=\"col_heading level0 col12\" >3.5U</th>\n",
       "      <th id=\"T_cbc44_level0_col13\" class=\"col_heading level0 col13\" >4.5U</th>\n",
       "      <th id=\"T_cbc44_level0_col14\" class=\"col_heading level0 col14\" >BTTS</th>\n",
       "      <th id=\"T_cbc44_level0_col15\" class=\"col_heading level0 col15\" >HT1</th>\n",
       "      <th id=\"T_cbc44_level0_col16\" class=\"col_heading level0 col16\" >HTX</th>\n",
       "      <th id=\"T_cbc44_level0_col17\" class=\"col_heading level0 col17\" >HT2</th>\n",
       "      <th id=\"T_cbc44_level0_col18\" class=\"col_heading level0 col18\" >HTR</th>\n",
       "      <th id=\"T_cbc44_level0_col19\" class=\"col_heading level0 col19\" >HTDC1X</th>\n",
       "      <th id=\"T_cbc44_level0_col20\" class=\"col_heading level0 col20\" >HTDC12</th>\n",
       "      <th id=\"T_cbc44_level0_col21\" class=\"col_heading level0 col21\" >HTDCX2</th>\n",
       "      <th id=\"T_cbc44_level0_col22\" class=\"col_heading level0 col22\" >HT0.5O</th>\n",
       "      <th id=\"T_cbc44_level0_col23\" class=\"col_heading level0 col23\" >HT1.5U</th>\n",
       "      <th id=\"T_cbc44_level0_col24\" class=\"col_heading level0 col24\" >H0.5O</th>\n",
       "      <th id=\"T_cbc44_level0_col25\" class=\"col_heading level0 col25\" >A0.5O</th>\n",
       "      <th id=\"T_cbc44_level0_col26\" class=\"col_heading level0 col26\" >H1.5O</th>\n",
       "      <th id=\"T_cbc44_level0_col27\" class=\"col_heading level0 col27\" >A1.5O</th>\n",
       "      <th id=\"T_cbc44_level0_col28\" class=\"col_heading level0 col28\" >H2.5U</th>\n",
       "      <th id=\"T_cbc44_level0_col29\" class=\"col_heading level0 col29\" >A2.5U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_cbc44_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_cbc44_row0_col0\" class=\"data row0 col0\" >Brazil</td>\n",
       "      <td id=\"T_cbc44_row0_col1\" class=\"data row0 col1\" >Fortaleza</td>\n",
       "      <td id=\"T_cbc44_row0_col2\" class=\"data row0 col2\" >Atletico MG</td>\n",
       "      <td id=\"T_cbc44_row0_col3\" class=\"data row0 col3\" >59.130000</td>\n",
       "      <td id=\"T_cbc44_row0_col4\" class=\"data row0 col4\" >22.620000</td>\n",
       "      <td id=\"T_cbc44_row0_col5\" class=\"data row0 col5\" >18.230000</td>\n",
       "      <td id=\"T_cbc44_row0_col6\" class=\"data row0 col6\" >1-1</td>\n",
       "      <td id=\"T_cbc44_row0_col7\" class=\"data row0 col7\" >81.750000</td>\n",
       "      <td id=\"T_cbc44_row0_col8\" class=\"data row0 col8\" >77.360000</td>\n",
       "      <td id=\"T_cbc44_row0_col9\" class=\"data row0 col9\" >40.850000</td>\n",
       "      <td id=\"T_cbc44_row0_col10\" class=\"data row0 col10\" >78.850000</td>\n",
       "      <td id=\"T_cbc44_row0_col11\" class=\"data row0 col11\" >55.300000</td>\n",
       "      <td id=\"T_cbc44_row0_col12\" class=\"data row0 col12\" >67.050000</td>\n",
       "      <td id=\"T_cbc44_row0_col13\" class=\"data row0 col13\" >83.240000</td>\n",
       "      <td id=\"T_cbc44_row0_col14\" class=\"data row0 col14\" >53.510000</td>\n",
       "      <td id=\"T_cbc44_row0_col15\" class=\"data row0 col15\" >48.790000</td>\n",
       "      <td id=\"T_cbc44_row0_col16\" class=\"data row0 col16\" >35.720000</td>\n",
       "      <td id=\"T_cbc44_row0_col17\" class=\"data row0 col17\" >14.630000</td>\n",
       "      <td id=\"T_cbc44_row0_col18\" class=\"data row0 col18\" >0-0</td>\n",
       "      <td id=\"T_cbc44_row0_col19\" class=\"data row0 col19\" >84.510000</td>\n",
       "      <td id=\"T_cbc44_row0_col20\" class=\"data row0 col20\" >63.420000</td>\n",
       "      <td id=\"T_cbc44_row0_col21\" class=\"data row0 col21\" >50.350000</td>\n",
       "      <td id=\"T_cbc44_row0_col22\" class=\"data row0 col22\" >79.800000</td>\n",
       "      <td id=\"T_cbc44_row0_col23\" class=\"data row0 col23\" >44.030000</td>\n",
       "      <td id=\"T_cbc44_row0_col24\" class=\"data row0 col24\" >85.360000</td>\n",
       "      <td id=\"T_cbc44_row0_col25\" class=\"data row0 col25\" >62.220000</td>\n",
       "      <td id=\"T_cbc44_row0_col26\" class=\"data row0 col26\" >57.250000</td>\n",
       "      <td id=\"T_cbc44_row0_col27\" class=\"data row0 col27\" >25.450000</td>\n",
       "      <td id=\"T_cbc44_row0_col28\" class=\"data row0 col28\" >69.760000</td>\n",
       "      <td id=\"T_cbc44_row0_col29\" class=\"data row0 col29\" >92.430000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbc44_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_cbc44_row1_col0\" class=\"data row1 col0\" >Brazil</td>\n",
       "      <td id=\"T_cbc44_row1_col1\" class=\"data row1 col1\" >Sao Paulo</td>\n",
       "      <td id=\"T_cbc44_row1_col2\" class=\"data row1 col2\" >Vasco da Gama</td>\n",
       "      <td id=\"T_cbc44_row1_col3\" class=\"data row1 col3\" >56.290000</td>\n",
       "      <td id=\"T_cbc44_row1_col4\" class=\"data row1 col4\" >24.490000</td>\n",
       "      <td id=\"T_cbc44_row1_col5\" class=\"data row1 col5\" >19.210000</td>\n",
       "      <td id=\"T_cbc44_row1_col6\" class=\"data row1 col6\" >1-0</td>\n",
       "      <td id=\"T_cbc44_row1_col7\" class=\"data row1 col7\" >80.780000</td>\n",
       "      <td id=\"T_cbc44_row1_col8\" class=\"data row1 col8\" >75.500000</td>\n",
       "      <td id=\"T_cbc44_row1_col9\" class=\"data row1 col9\" >43.700000</td>\n",
       "      <td id=\"T_cbc44_row1_col10\" class=\"data row1 col10\" >74.470000</td>\n",
       "      <td id=\"T_cbc44_row1_col11\" class=\"data row1 col11\" >49.180000</td>\n",
       "      <td id=\"T_cbc44_row1_col12\" class=\"data row1 col12\" >72.700000</td>\n",
       "      <td id=\"T_cbc44_row1_col13\" class=\"data row1 col13\" >87.150000</td>\n",
       "      <td id=\"T_cbc44_row1_col14\" class=\"data row1 col14\" >49.610000</td>\n",
       "      <td id=\"T_cbc44_row1_col15\" class=\"data row1 col15\" >48.690000</td>\n",
       "      <td id=\"T_cbc44_row1_col16\" class=\"data row1 col16\" >39.830000</td>\n",
       "      <td id=\"T_cbc44_row1_col17\" class=\"data row1 col17\" >11.110000</td>\n",
       "      <td id=\"T_cbc44_row1_col18\" class=\"data row1 col18\" >0-0</td>\n",
       "      <td id=\"T_cbc44_row1_col19\" class=\"data row1 col19\" >88.520000</td>\n",
       "      <td id=\"T_cbc44_row1_col20\" class=\"data row1 col20\" >59.800000</td>\n",
       "      <td id=\"T_cbc44_row1_col21\" class=\"data row1 col21\" >50.940000</td>\n",
       "      <td id=\"T_cbc44_row1_col22\" class=\"data row1 col22\" >72.080000</td>\n",
       "      <td id=\"T_cbc44_row1_col23\" class=\"data row1 col23\" >58.170000</td>\n",
       "      <td id=\"T_cbc44_row1_col24\" class=\"data row1 col24\" >82.270000</td>\n",
       "      <td id=\"T_cbc44_row1_col25\" class=\"data row1 col25\" >59.770000</td>\n",
       "      <td id=\"T_cbc44_row1_col26\" class=\"data row1 col26\" >51.610000</td>\n",
       "      <td id=\"T_cbc44_row1_col27\" class=\"data row1 col27\" >23.140000</td>\n",
       "      <td id=\"T_cbc44_row1_col28\" class=\"data row1 col28\" >74.910000</td>\n",
       "      <td id=\"T_cbc44_row1_col29\" class=\"data row1 col29\" >93.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_cbc44_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_cbc44_row2_col0\" class=\"data row2 col0\" >England3</td>\n",
       "      <td id=\"T_cbc44_row2_col1\" class=\"data row2 col1\" >Shrewsbury</td>\n",
       "      <td id=\"T_cbc44_row2_col2\" class=\"data row2 col2\" >Exeter City</td>\n",
       "      <td id=\"T_cbc44_row2_col3\" class=\"data row2 col3\" >18.060000</td>\n",
       "      <td id=\"T_cbc44_row2_col4\" class=\"data row2 col4\" >30.030000</td>\n",
       "      <td id=\"T_cbc44_row2_col5\" class=\"data row2 col5\" >51.910000</td>\n",
       "      <td id=\"T_cbc44_row2_col6\" class=\"data row2 col6\" >0-1</td>\n",
       "      <td id=\"T_cbc44_row2_col7\" class=\"data row2 col7\" >48.090000</td>\n",
       "      <td id=\"T_cbc44_row2_col8\" class=\"data row2 col8\" >69.970000</td>\n",
       "      <td id=\"T_cbc44_row2_col9\" class=\"data row2 col9\" >81.940000</td>\n",
       "      <td id=\"T_cbc44_row2_col10\" class=\"data row2 col10\" >60.900000</td>\n",
       "      <td id=\"T_cbc44_row2_col11\" class=\"data row2 col11\" >33.000000</td>\n",
       "      <td id=\"T_cbc44_row2_col12\" class=\"data row2 col12\" >85.260000</td>\n",
       "      <td id=\"T_cbc44_row2_col13\" class=\"data row2 col13\" >94.510000</td>\n",
       "      <td id=\"T_cbc44_row2_col14\" class=\"data row2 col14\" >37.330000</td>\n",
       "      <td id=\"T_cbc44_row2_col15\" class=\"data row2 col15\" >19.530000</td>\n",
       "      <td id=\"T_cbc44_row2_col16\" class=\"data row2 col16\" >48.930000</td>\n",
       "      <td id=\"T_cbc44_row2_col17\" class=\"data row2 col17\" >31.510000</td>\n",
       "      <td id=\"T_cbc44_row2_col18\" class=\"data row2 col18\" >0-0</td>\n",
       "      <td id=\"T_cbc44_row2_col19\" class=\"data row2 col19\" >68.460000</td>\n",
       "      <td id=\"T_cbc44_row2_col20\" class=\"data row2 col20\" >51.040000</td>\n",
       "      <td id=\"T_cbc44_row2_col21\" class=\"data row2 col21\" >80.440000</td>\n",
       "      <td id=\"T_cbc44_row2_col22\" class=\"data row2 col22\" >59.130000</td>\n",
       "      <td id=\"T_cbc44_row2_col23\" class=\"data row2 col23\" >77.690000</td>\n",
       "      <td id=\"T_cbc44_row2_col24\" class=\"data row2 col24\" >49.360000</td>\n",
       "      <td id=\"T_cbc44_row2_col25\" class=\"data row2 col25\" >73.920000</td>\n",
       "      <td id=\"T_cbc44_row2_col26\" class=\"data row2 col26\" >14.910000</td>\n",
       "      <td id=\"T_cbc44_row2_col27\" class=\"data row2 col27\" >38.870000</td>\n",
       "      <td id=\"T_cbc44_row2_col28\" class=\"data row2 col28\" >96.820000</td>\n",
       "      <td id=\"T_cbc44_row2_col29\" class=\"data row2 col29\" >84.680000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1311c5ee570>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ft1, ftx, ft2, ft_score = [], [], [], []\n",
    "over_15, over_25, under_35, under_45, btts = [], [], [], [], []\n",
    "ht1, htx, ht2, ht_score, ht_over05, ht_under15 = [], [], [], [], [], []\n",
    "ho05, ao05, ho15, ao15, hu25, au25 = [], [], [], [], [], []\n",
    "\n",
    "# Helper function to calculate total goals for each score\n",
    "def total_goals(i, j):\n",
    "    return i + j\n",
    "\n",
    "for i in range(len(next_matches)):\n",
    "    my_matrix = full_time_matrices[i]\n",
    "    ht_matrix = half_time_matrices[i]\n",
    "\n",
    "    ft1.append(round(np.sum(np.tril(my_matrix, k=-1)) * 100, 2)) # Sum of lower triangular values (home win)\n",
    "    ftx.append(round(np.sum(np.diag(my_matrix)) * 100, 2)) # Sum of diagonal values (draw)\n",
    "    ft2.append(round(np.sum(np.triu(my_matrix, k=1)) * 100, 2)) # Sum of higher triangular values (away_win)\n",
    "    \n",
    "    max_score = np.unravel_index(np.argmax(my_matrix), my_matrix.shape) # Find the index of the maximum score\n",
    "    home_goals, away_goals = max_score\n",
    "    ft_score.append(f\"{home_goals}-{away_goals}\") # Format the score as 'home-away'\n",
    "\n",
    "    # Calculate the probabilities\n",
    "    over_15.append(round(np.sum([my_matrix[i, j] for i in range(my_matrix.shape[0]) for j in range(my_matrix.shape[1]) if total_goals(i, j) > 1.5]) * 100, 2))\n",
    "    over_25.append(round(np.sum([my_matrix[i, j] for i in range(my_matrix.shape[0]) for j in range(my_matrix.shape[1]) if total_goals(i, j) > 2.5]) * 100, 2))\n",
    "    under_35.append(round(np.sum([my_matrix[i, j] for i in range(my_matrix.shape[0]) for j in range(my_matrix.shape[1]) if total_goals(i, j) <= 3.5]) * 100, 2))\n",
    "    under_45.append(round(np.sum([my_matrix[i, j] for i in range(my_matrix.shape[0]) for j in range(my_matrix.shape[1]) if total_goals(i, j) <= 4.5]) * 100, 2))\n",
    "\n",
    "    # Calculate BTTS (both teams to score and goals != 0)\n",
    "    btts.append(round(np.sum([my_matrix[i, j] for i in range(1, my_matrix.shape[0]) for j in range(1, my_matrix.shape[1])]) * 100, 2)) \n",
    "\n",
    "    # Calculate statistics for Half Time\n",
    "    ht1.append(round(np.sum(np.tril(ht_matrix, k=-1)) * 100, 2)) # Sum of lower triangular values (home win)\n",
    "    htx.append(round(np.sum(np.diag(ht_matrix)) * 100, 2)) # Sum of diagonal values (draw)\n",
    "    ht2.append(round(np.sum(np.triu(ht_matrix, k=1)) * 100, 2)) # Sum of higher triangular values (away_win)\n",
    "\n",
    "    ht_max_score = np.unravel_index(np.argmax(ht_matrix), ht_matrix.shape) # Find the index of the maximum score\n",
    "    ht_hogs, ht_awgs = ht_max_score\n",
    "    ht_score.append(f\"{ht_hogs}-{ht_awgs}\") # Format the score as 'home-away'\n",
    "\n",
    "    ht_over05.append(round(np.sum([ht_matrix[i, j] for i in range(ht_matrix.shape[0]) for j in range(ht_matrix.shape[1]) if total_goals(i, j) > 0.5]) * 100, 2))   \n",
    "    ht_under15.append(round(np.sum([ht_matrix[i, j] for i in range(ht_matrix.shape[0]) for j in range(ht_matrix.shape[1]) if total_goals(i, j) < 1.5]) * 100, 2)) \n",
    "\n",
    "    ho05.append(round(np.sum(my_matrix[1:,:]) * 100, 2))\n",
    "    ao05.append(round(np.sum(my_matrix[:,1:]) * 100, 2))\n",
    "    ho15.append(round(np.sum(my_matrix[2:,:]) * 100, 2))\n",
    "    ao15.append(round(np.sum(my_matrix[:,2:]) * 100, 2))\n",
    "    hu25.append(round(np.sum(my_matrix[:3,:]) * 100, 2))\n",
    "    au25.append(round(np.sum(my_matrix[:,:3]) * 100, 2))\n",
    "    \n",
    "\n",
    "# Combine lists into a DataFrame\n",
    "final_results = pd.DataFrame({\n",
    "    'League': next_matches['League'], 'Home': next_matches['Home'], 'Away': next_matches['Away'],\n",
    "    'FT1': ft1, 'FTX': ftx, 'FT2': ft2, 'FTR': ft_score,\n",
    "    'DC1X': [x + y for x, y in zip(ft1, ftx)], 'DC12': [x + y for x, y in zip(ft1, ft2)], 'DCX2': [x + y for x, y in zip(ftx, ft2)],\n",
    "    '1.5O': over_15, '2.5O': over_25, '3.5U': under_35, '4.5U': under_45, 'BTTS': btts,\n",
    "    'HT1': ht1, 'HTX': htx, 'HT2': ht2, 'HTR': ht_score,\n",
    "    'HTDC1X': [x + y for x, y in zip(ht1, htx)], 'HTDC12': [x + y for x, y in zip(ht1, ht2)], 'HTDCX2': [x + y for x, y in zip(htx, ht2)],\n",
    "    'HT0.5O': ht_over05, 'HT1.5U': ht_under15, 'H0.5O':ho05, 'A0.5O':ao05, 'H1.5O':ho15, 'A1.5O':ao15, 'H2.5U':hu25, 'A2.5U':au25\n",
    "})\n",
    "\n",
    "# Function to highlight values higher than threshold\n",
    "def highlight_values(value):\n",
    "    if isinstance(value, str):\n",
    "        return ''  # Return empty string for NaN values\n",
    "    elif value > threshold:\n",
    "    #color = 'red'\n",
    "        return 'background-color: red'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Apply the style\n",
    "with pd.option_context('display.precision', 2):\n",
    "    styled_df = final_results.style.applymap(highlight_values)\n",
    "styled_df.to_excel(given_date + \".xlsx\", index = False)\n",
    "# Display the styled DataFrame\n",
    "from IPython.display import display, HTML\n",
    "display(styled_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
