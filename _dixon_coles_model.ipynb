{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calling Necessary Libraries AND Getting Today's Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from dateutil import parser\n",
    "from scipy.stats import poisson\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Get today's date\n",
    "given_date = \"2024-10-14\" #year-month-day\n",
    "threshold = 80 #threshold for percentages to highlight in final dataframe (between 1 and 100)\n",
    "\n",
    "wanted_leagues = ['argentina', 'austria', 'belgium',\n",
    "                  'brazil', 'denmark', 'portugal2',\n",
    "                  'england', 'england2', 'england3', 'england4', 'england5', 'france', 'france2',\n",
    "                  'germany', 'germany2', 'greece', 'italy', 'italy2',\n",
    "                   'mexico', 'netherlands', 'norway','poland', 'portugal',\n",
    "                  'scotland', 'spain', 'spain2', 'sweden',\n",
    "                  'switzerland', 'turkey', 'usa']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating Days between given date and today\n",
    "# Today's date\n",
    "today = datetime.now().date()\n",
    "\n",
    "# Specific date\n",
    "specific_date = datetime.strptime(given_date, \"%Y-%m-%d\").date()\n",
    "\n",
    "# Calculate the difference in days\n",
    "difference = specific_date - today\n",
    "\n",
    "# Add one day to the difference\n",
    "days_until_specific_date = difference.days + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Today's Matches and Leagues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.soccerstats.com/matches.asp?matchday=\" + str(days_until_specific_date) + \"&listing=2\"\n",
    "page = requests.get(URL)\n",
    "liqa = []\n",
    "soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "results = soup.find(id=\"btable\")\n",
    "sth = results.find_all(\"tr\", attrs={'height': '34'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>league</th>\n",
       "      <th>home_team</th>\n",
       "      <th>away_team</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [league, home_team, away_team]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize lists to store extracted data\n",
    "league_list = []\n",
    "home_team_list = []\n",
    "away_team_list = []\n",
    "\n",
    "# Iterate through each <tr> element\n",
    "for tr_element in sth:\n",
    "    # Find the <td> element with sorttable_customkey attribute\n",
    "    td_element = tr_element.find('td', attrs={'sorttable_customkey': True})\n",
    "    \n",
    "    # Check if <td> element exists and contains an <img> element with the alt attribute\n",
    "    if td_element and td_element.find('img', alt=True):\n",
    "        # Extract league info\n",
    "        league = td_element['sorttable_customkey']\n",
    "        if league in wanted_leagues:\n",
    "            league_list.append(league)\n",
    "        \n",
    "        # Find <td> elements with class \"steam\"\n",
    "        td_elements_steam = tr_element.find_all('td', class_='steam')\n",
    "        \n",
    "        # Extract home and away team info\n",
    "        if len(td_elements_steam) == 2 and league in wanted_leagues:\n",
    "            home_team = td_elements_steam[0].get_text(strip=True)\n",
    "            away_team = td_elements_steam[1].get_text(strip=True)\n",
    "            home_team_list.append(home_team)\n",
    "            away_team_list.append(away_team)\n",
    "        else:\n",
    "            continue\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "# Create DataFrame\n",
    "matches = pd.DataFrame({\n",
    "    'league': league_list,\n",
    "    'home_team': home_team_list,\n",
    "    'away_team': away_team_list\n",
    "})\n",
    "\n",
    "# Display DataFrame\n",
    "matches.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Date and Collecting Leagues for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import parser\n",
    "\n",
    "day_abbreviations = {0: \"Mo\", 1: \"Tu\", 2: \"We\", 3: \"Th\", 4: \"Fr\", 5: \"Sa\", 6: \"Su\"}\n",
    "given_date_parsed = parser.parse(given_date)\n",
    "\n",
    "# Manually format the day to remove leading zeros\n",
    "day = given_date_parsed.day\n",
    "month = given_date_parsed.strftime('%b')\n",
    "\n",
    "# Format the date as \"Su 1 Oct\" or \"Tu 10 Oct\" without leading zero for single-digit days\n",
    "formatted_date = f\"{day_abbreviations[given_date_parsed.weekday()]} {day} {month}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping the Web for the League Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>League</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>FT</th>\n",
       "      <th>HT</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTTG</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTTG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fr 10 May</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Sarmiento</td>\n",
       "      <td>Instituto</td>\n",
       "      <td>1 - 2</td>\n",
       "      <td>(0-1)</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sa 11 May</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Argentinos Jrs</td>\n",
       "      <td>Rosario Central</td>\n",
       "      <td>3 - 2</td>\n",
       "      <td>(2-2)</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sa 11 May</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Newells</td>\n",
       "      <td>Platense</td>\n",
       "      <td>2 - 0</td>\n",
       "      <td>(0-0)</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sa 11 May</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Huracan</td>\n",
       "      <td>Defensa y J.</td>\n",
       "      <td>3 - 1</td>\n",
       "      <td>(1-0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sa 11 May</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>Godoy Cruz</td>\n",
       "      <td>Barracas C.</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>(0-0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3385</th>\n",
       "      <td>Su 6 Oct</td>\n",
       "      <td>Usa</td>\n",
       "      <td>LA Galaxy</td>\n",
       "      <td>Austin</td>\n",
       "      <td>2 - 1</td>\n",
       "      <td>(1-0)</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3386</th>\n",
       "      <td>Su 6 Oct</td>\n",
       "      <td>Usa</td>\n",
       "      <td>SJ Earthquakes</td>\n",
       "      <td>Real Salt Lake</td>\n",
       "      <td>0 - 1</td>\n",
       "      <td>(0-0)</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3387</th>\n",
       "      <td>Su 6 Oct</td>\n",
       "      <td>Usa</td>\n",
       "      <td>New York City</td>\n",
       "      <td>Nashville SC</td>\n",
       "      <td>3 - 1</td>\n",
       "      <td>(3-0)</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3388</th>\n",
       "      <td>Mo 7 Oct</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Portland</td>\n",
       "      <td>Dallas</td>\n",
       "      <td>0 - 0</td>\n",
       "      <td>(0-0)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3389</th>\n",
       "      <td>Su 13 Oct</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Columbus Crew</td>\n",
       "      <td>New England</td>\n",
       "      <td>4 - 0</td>\n",
       "      <td>(2-0)</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date     League            Home             Away     FT     HT  \\\n",
       "0     Fr 10 May  Argentina       Sarmiento        Instituto  1 - 2  (0-1)   \n",
       "1     Sa 11 May  Argentina  Argentinos Jrs  Rosario Central  3 - 2  (2-2)   \n",
       "2     Sa 11 May  Argentina         Newells         Platense  2 - 0  (0-0)   \n",
       "3     Sa 11 May  Argentina         Huracan     Defensa y J.  3 - 1  (1-0)   \n",
       "4     Sa 11 May  Argentina      Godoy Cruz      Barracas C.  0 - 1  (0-0)   \n",
       "3385   Su 6 Oct        Usa       LA Galaxy           Austin  2 - 1  (1-0)   \n",
       "3386   Su 6 Oct        Usa  SJ Earthquakes   Real Salt Lake  0 - 1  (0-0)   \n",
       "3387   Su 6 Oct        Usa   New York City     Nashville SC  3 - 1  (3-0)   \n",
       "3388   Mo 7 Oct        Usa        Portland           Dallas  0 - 0  (0-0)   \n",
       "3389  Su 13 Oct        Usa   Columbus Crew      New England  4 - 0  (2-0)   \n",
       "\n",
       "      FTHG  FTAG  FTTG  HTHG  HTAG  HTTG  \n",
       "0        1     2     3     0     1     1  \n",
       "1        3     2     5     2     2     4  \n",
       "2        2     0     2     0     0     0  \n",
       "3        3     1     4     1     0     1  \n",
       "4        0     1     1     0     0     0  \n",
       "3385     2     1     3     1     0     1  \n",
       "3386     0     1     1     0     0     0  \n",
       "3387     3     1     4     3     0     3  \n",
       "3388     0     0     0     0     0     0  \n",
       "3389     4     0     4     2     0     2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final =  pd.DataFrame()\n",
    "liqa = ''\n",
    "unique_leagues = wanted_leagues#matches['league'].unique().tolist()\n",
    "next_matches = pd.DataFrame()\n",
    "\n",
    "for i in unique_leagues:\n",
    "    URL = \"https://www.soccerstats.com/results.asp?league=\" + i + \"&pmtype=bydate\"\n",
    "    page = requests.get(URL)\n",
    "    liqa = i\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    results = soup.find(id=\"btable\")\n",
    "    sth = results.find_all(\"tr\", class_=\"odd\")\n",
    "    sth\n",
    "\n",
    "\n",
    "    date, league, home, away, ft, ht = [], [], [], [], [],[]\n",
    "    for i in sth:\n",
    "        date.append(i.find_all(\"td\", align = 'right')[0].get_text(strip=True))\n",
    "        league.append(liqa.capitalize())\n",
    "        home.append(i.find_all(\"td\", align = 'right')[1].get_text(strip=True))\n",
    "        away.append(i.find(\"td\", align = \"left\").get_text(strip = True))\n",
    "        ft.append(i.find_all(\"td\", align = 'center')[0].get_text(strip = True))\n",
    "        try:\n",
    "            ht.append(i.find_all(\"td\", align = 'center')[2].get_text(strip = True))\n",
    "        except IndexError as e:\n",
    "            ht.append('NA')#print(\"Last output before error occurred:\", i.find_all(\"td\", align = 'center'))\n",
    "\n",
    "    data = {'Date': date, 'League': league,'Home': home, 'Away': away, 'FT': ft, 'HT': ht}\n",
    "\n",
    "# Create a DataFrame from the dictionary\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "# Replace empty strings with NaN\n",
    "    next_df = df[(df['Date'] == formatted_date) & (df['HT'] == '')]\n",
    "    next_matches = pd.concat([next_matches, next_df], ignore_index = True)\n",
    "    df.replace('', pd.NA, inplace=True)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "    df_cleaned = df.dropna()\n",
    "\n",
    "#For Half-Time Results\n",
    "    hthg, htag = [], []\n",
    "    for i in df_cleaned['HT']:\n",
    "        if i == 'NA':\n",
    "            hthg.append('NA')\n",
    "            htag.append('NA')\n",
    "        elif i == '+' or i == '-':\n",
    "            hthg.append('NA')\n",
    "            htag.append('NA')\n",
    "        else:\n",
    "            try:\n",
    "                hthg.append(int(i[1]))\n",
    "                htag.append(int(i[3]))\n",
    "            except IndexError as e:\n",
    "                print(\"Last output before error occurred:\", i)\n",
    "\n",
    "\n",
    "\n",
    "#For Full-Time Results\n",
    "    hg, ag, tg = [], [], []\n",
    "    for i in df_cleaned['FT']:\n",
    "        if len(i) < 5 or ':' in i:\n",
    "            hg.append('NA')\n",
    "            ag.append('NA')\n",
    "            tg.append('NA')\n",
    "        else:\n",
    "            try:\n",
    "                hghg = int(i.split(' - ')[0])\n",
    "                hg.append(hghg)\n",
    "                agag = int(i.split(' - ')[1])\n",
    "                ag.append(agag)\n",
    "                tg.append(hghg + agag)\n",
    "            except:\n",
    "                print(hghg + agag)\n",
    "\n",
    "    \n",
    "    df_cleaned['FTHG'], df_cleaned['FTAG'], df_cleaned['FTTG'] = hg, ag, tg\n",
    "    df_cleaned['HTHG'], df_cleaned['HTAG'] = hthg, htag\n",
    "    df_cleaned['HTTG'] = df_cleaned['HTHG'] + df_cleaned['HTAG']\n",
    "    \n",
    "    final = pd.concat([final, df_cleaned], ignore_index=True)\n",
    "    \n",
    "final = final[final['HT'] != 'NA']\n",
    "combined_df = pd.concat([final.head(), final.tail()])\n",
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>League</th>\n",
       "      <th>Home</th>\n",
       "      <th>Away</th>\n",
       "      <th>FT</th>\n",
       "      <th>HT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mo 14 Oct</td>\n",
       "      <td>Portugal2</td>\n",
       "      <td>Portimonense</td>\n",
       "      <td>Benfica B</td>\n",
       "      <td>18:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mo 14 Oct</td>\n",
       "      <td>Spain2</td>\n",
       "      <td>Sporting Gijon</td>\n",
       "      <td>Castellon</td>\n",
       "      <td>19:30</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mo 14 Oct</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Los Angeles FC</td>\n",
       "      <td>00:30</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mo 14 Oct</td>\n",
       "      <td>Portugal2</td>\n",
       "      <td>Portimonense</td>\n",
       "      <td>Benfica B</td>\n",
       "      <td>18:00</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mo 14 Oct</td>\n",
       "      <td>Spain2</td>\n",
       "      <td>Sporting Gijon</td>\n",
       "      <td>Castellon</td>\n",
       "      <td>19:30</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mo 14 Oct</td>\n",
       "      <td>Usa</td>\n",
       "      <td>Vancouver</td>\n",
       "      <td>Los Angeles FC</td>\n",
       "      <td>00:30</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date     League            Home            Away     FT HT\n",
       "0  Mo 14 Oct  Portugal2    Portimonense       Benfica B  18:00   \n",
       "1  Mo 14 Oct     Spain2  Sporting Gijon       Castellon  19:30   \n",
       "2  Mo 14 Oct        Usa       Vancouver  Los Angeles FC  00:30   \n",
       "0  Mo 14 Oct  Portugal2    Portimonense       Benfica B  18:00   \n",
       "1  Mo 14 Oct     Spain2  Sporting Gijon       Castellon  19:30   \n",
       "2  Mo 14 Oct        Usa       Vancouver  Los Angeles FC  00:30   "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_leagues = next_matches['League'].unique().tolist()\n",
    "pd.concat([next_matches.head(), next_matches.tail()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Functions Needed for Dixon-Coles Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "from scipy.stats import poisson\n",
    "\n",
    "def rho_correction(x, y, lambda_x, mu_y, rho):\n",
    "    if x==0 and y==0:\n",
    "        return 1- (lambda_x * mu_y * rho)\n",
    "    elif x==0 and y==1:\n",
    "        return 1 + (lambda_x * rho)\n",
    "    elif x==1 and y==0:\n",
    "        return 1 + (mu_y * rho)\n",
    "    elif x==1 and y==1:\n",
    "        return 1 - rho\n",
    "    else:\n",
    "        return 1.0\n",
    "\n",
    "def dc_log_like(x, y, alpha_x, beta_x, alpha_y, beta_y, rho, gamma):\n",
    "    lambda_x, mu_y = np.exp(alpha_x + beta_y + gamma), np.exp(alpha_y + beta_x) \n",
    "    return (np.log(rho_correction(x, y, lambda_x, mu_y, rho)) + \n",
    "            np.log(poisson.pmf(x, lambda_x)) + np.log(poisson.pmf(y, mu_y)))\n",
    "\n",
    "\n",
    "\n",
    "def solve_parameters(dataset, half_or_full = 'full', debug = False, init_vals=None, options={'disp': True, 'maxiter':100},\n",
    "                     constraints = [{'type':'eq', 'fun': lambda x: sum(x[:20])-20}] , **kwargs):\n",
    "    teams = np.sort(dataset['Home'].unique())\n",
    "    # check for no weirdness in dataset\n",
    "    away_teams = np.sort(dataset['Away'].unique())\n",
    "    if not np.array_equal(teams, away_teams):\n",
    "        raise ValueError(\"Something's not right\")\n",
    "    n_teams = len(teams)\n",
    "    if init_vals is None:\n",
    "        # random initialisation of model parameters\n",
    "        init_vals = np.concatenate((np.random.uniform(0,1,(n_teams)), # attack strength\n",
    "                                      np.random.uniform(0,-1,(n_teams)), # defence strength\n",
    "                                      np.array([0, 1.0]) # rho (score correction), gamma (home advantage)\n",
    "                                     ))\n",
    "\n",
    "    def estimate_paramters(params):\n",
    "        score_coefs = dict(zip(teams, params[:n_teams]))\n",
    "        defend_coefs = dict(zip(teams, params[n_teams:(2*n_teams)]))\n",
    "        rho, gamma = params[-2:]\n",
    "        if half_or_full == 'full':\n",
    "            log_like = [dc_log_like(row.FTHG, row.FTAG, score_coefs[row.Home], defend_coefs[row.Home],\n",
    "                        score_coefs[row.Away], defend_coefs[row.Away], rho, gamma) for row in dataset.itertuples()]\n",
    "        elif half_or_full == 'half':\n",
    "            log_like = [dc_log_like(row.HTHG, row.HTAG, score_coefs[row.Home], defend_coefs[row.Home],\n",
    "                        score_coefs[row.Away], defend_coefs[row.Away], rho, gamma) for row in dataset.itertuples()]\n",
    "\n",
    "        return -sum(log_like)\n",
    "    opt_output = minimize(estimate_paramters, init_vals, options=options, constraints = constraints, **kwargs)\n",
    "    if debug:\n",
    "        # sort of hacky way to investigate the output of the optimisation process\n",
    "        return opt_output\n",
    "    else:\n",
    "        return dict(zip([\"attack_\"+team for team in teams] + \n",
    "                        [\"defence_\"+team for team in teams] +\n",
    "                        ['rho', 'home_adv'],\n",
    "                        opt_output.x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Lambda Values for Dixon-Coles Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 172.76255526686867\n",
      "            Iterations: 42\n",
      "            Function evaluations: 1683\n",
      "            Gradient evaluations: 42\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 119.88549022837012\n",
      "            Iterations: 29\n",
      "            Function evaluations: 1162\n",
      "            Gradient evaluations: 29\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 238.2931510367431\n",
      "            Iterations: 73\n",
      "            Function evaluations: 3529\n",
      "            Gradient evaluations: 73\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 146.6649923795641\n",
      "            Iterations: 40\n",
      "            Function evaluations: 1932\n",
      "            Gradient evaluations: 40\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 1426.21153064343\n",
      "            Iterations: 83\n",
      "            Function evaluations: 5190\n",
      "            Gradient evaluations: 83\n",
      "Optimization terminated successfully    (Exit mode 0)\n",
      "            Current function value: 987.7376335474314\n",
      "            Iterations: 92\n",
      "            Function evaluations: 5735\n",
      "            Gradient evaluations: 92\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "stats_df = pd.DataFrame()\n",
    "full_time_models = []\n",
    "half_time_models = []\n",
    "\n",
    "for league in next_leagues:\n",
    "    league_df = final[final['League'] == league.capitalize()]\n",
    "    \n",
    "    full_time_estimates = solve_parameters(league_df, half_or_full = 'full')\n",
    "    full_time_models.append(full_time_estimates)\n",
    "\n",
    "    half_time_estimates = solve_parameters(league_df, half_or_full = 'half')\n",
    "    half_time_models.append(half_time_estimates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'attack_Atlanta Utd': 0.8366063035147298,\n",
       " 'attack_Austin': 0.7054100374773052,\n",
       " 'attack_CF Montreal': 0.9087846808615054,\n",
       " 'attack_Charlotte': 0.8112494844247118,\n",
       " 'attack_Chicago Fire': 0.7586131455111425,\n",
       " 'attack_Cincinnati': 1.0717505132299852,\n",
       " 'attack_Colorado Rapids': 1.1836066989340301,\n",
       " 'attack_Columbus Crew': 1.295190894774223,\n",
       " 'attack_DC United': 1.026908016322505,\n",
       " 'attack_Dallas': 1.0766862022414696,\n",
       " 'attack_Houston Dynamo': 0.8917804422466356,\n",
       " 'attack_Inter Miami': 1.3545496881886046,\n",
       " 'attack_LA Galaxy': 1.340176634537932,\n",
       " 'attack_Los Angeles FC': 1.2224153536055744,\n",
       " 'attack_Minnesota Utd': 1.1143012920456494,\n",
       " 'attack_Nashville SC': 0.6153879512441682,\n",
       " 'attack_New England': 0.6234631743179383,\n",
       " 'attack_New York City': 1.0206565436989614,\n",
       " 'attack_New York RB': 1.0314677867623516,\n",
       " 'attack_Orlando City': 1.1109951560605782,\n",
       " 'attack_Philadelphia': 1.193962272251305,\n",
       " 'attack_Portland': 1.2912641411540169,\n",
       " 'attack_Real Salt Lake': 1.251469160392484,\n",
       " 'attack_SJ Earthquakes': 0.8130548300257708,\n",
       " 'attack_Seattle': 0.9914262142721985,\n",
       " 'attack_Sporting KC': 1.0506741258777546,\n",
       " 'attack_St. Louis City': 1.0072878517086983,\n",
       " 'attack_Toronto': 0.7337361946996531,\n",
       " 'attack_Vancouver': 1.0469246142986144,\n",
       " 'defence_Atlanta Utd': -0.7604456434218224,\n",
       " 'defence_Austin': -0.8673775853280269,\n",
       " 'defence_CF Montreal': -0.4428972765426192,\n",
       " 'defence_Charlotte': -1.0059978077474816,\n",
       " 'defence_Chicago Fire': -0.5463436556306707,\n",
       " 'defence_Cincinnati': -0.7461733881477569,\n",
       " 'defence_Colorado Rapids': -0.6449113790877513,\n",
       " 'defence_Columbus Crew': -0.952515249302749,\n",
       " 'defence_DC United': -0.4087569894563733,\n",
       " 'defence_Dallas': -0.6320411946119502,\n",
       " 'defence_Houston Dynamo': -1.0186055031737375,\n",
       " 'defence_Inter Miami': -0.7608751336844669,\n",
       " 'defence_LA Galaxy': -0.775785090524742,\n",
       " 'defence_Los Angeles FC': -0.940082141194941,\n",
       " 'defence_Minnesota Utd': -0.8178174779009126,\n",
       " 'defence_Nashville SC': -0.6497886612994369,\n",
       " 'defence_New England': -0.4006947816949818,\n",
       " 'defence_New York City': -0.7554787415192314,\n",
       " 'defence_New York RB': -0.7380769538717464,\n",
       " 'defence_Orlando City': -0.7158129801028852,\n",
       " 'defence_Philadelphia': -0.6119064962958685,\n",
       " 'defence_Portland': -0.6486169306756754,\n",
       " 'defence_Real Salt Lake': -0.8195190650391241,\n",
       " 'defence_SJ Earthquakes': -0.3702588989703411,\n",
       " 'defence_Seattle': -1.1616731936141922,\n",
       " 'defence_Sporting KC': -0.5359792656539482,\n",
       " 'defence_St. Louis City': -0.5845525165714484,\n",
       " 'defence_Toronto': -0.5397266500448012,\n",
       " 'defence_Vancouver': -0.8185598526930564,\n",
       " 'rho': -0.13446567644453702,\n",
       " 'home_adv': 0.21007876160297353}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_time_models[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Probability Matrices for Half/Full Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.95142746e-02, 3.06875731e-02, 7.09180801e-02, 8.52983435e-02,\n",
       "        7.69459007e-02, 5.55290656e-02, 3.33944271e-02, 1.72139620e-02,\n",
       "        7.76418247e-03],\n",
       "       [1.30637219e-03, 4.44399549e-02, 6.46239498e-02, 7.77279342e-02,\n",
       "        7.01167885e-02, 5.06007430e-02, 3.04306007e-02, 1.56861862e-02,\n",
       "        7.07509478e-03],\n",
       "       [4.52293413e-03, 1.63201875e-02, 2.94442184e-02, 3.54147074e-02,\n",
       "        3.19468872e-02, 2.30549098e-02, 1.38649101e-02, 7.14700194e-03,\n",
       "        3.22358254e-03],\n",
       "       [1.37383804e-03, 4.95724540e-03, 8.94366050e-03, 1.07571923e-02,\n",
       "        9.70384437e-03, 7.00291250e-03, 4.21145662e-03, 2.17089678e-03,\n",
       "        9.79160913e-04],\n",
       "       [3.12976748e-04, 1.12931983e-03, 2.03747290e-03, 2.45061715e-03,\n",
       "        2.21065189e-03, 1.59534728e-03, 9.59420224e-04, 4.94556268e-04,\n",
       "        2.23064575e-04],\n",
       "       [5.70398793e-05, 2.05818060e-04, 3.71328571e-04, 4.46623935e-04,\n",
       "        4.02890367e-04, 2.90751364e-04, 1.74853928e-04, 9.01326697e-05,\n",
       "        4.06534240e-05],\n",
       "       [8.66291147e-06, 3.12585449e-05, 5.63953952e-05, 6.78308519e-05,\n",
       "        6.11888318e-05, 4.41577605e-05, 2.65558784e-05, 1.36888673e-05,\n",
       "        6.17422438e-06],\n",
       "       [1.12772281e-06, 4.06918323e-06, 7.34145486e-06, 8.83010280e-06,\n",
       "        7.96545614e-06, 5.74838077e-06, 3.45699825e-06, 1.78199303e-06,\n",
       "        8.03749834e-07],\n",
       "       [1.28454377e-07, 4.63504322e-07, 8.36235642e-07, 1.00580155e-06,\n",
       "        9.07313122e-07, 6.54774970e-07, 3.93772788e-07, 2.02979670e-07,\n",
       "        9.15519160e-08]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#First Function needs work to make it more understandable and a df rather than matrix!\n",
    "def dixon_coles_simulate_match(params_dict, homeTeam, awayTeam, max_goals=10):\n",
    "    team_avgs = [np.exp(params_dict['attack_'+homeTeam] + params_dict['defence_'+awayTeam] + params_dict['home_adv']),\n",
    "                 np.exp(params_dict['defence_'+homeTeam] + params_dict['attack_'+awayTeam])]\n",
    "    team_pred = [[poisson.pmf(i, team_avg) for i in range(0, max_goals+1)] for team_avg in team_avgs]\n",
    "    output_matrix = np.outer(np.array(team_pred[0]), np.array(team_pred[1]))\n",
    "    correction_matrix = np.array([[rho_correction(home_goals, away_goals, team_avgs[0],\n",
    "                                                   team_avgs[1], params_dict['rho']) for away_goals in range(2)]\n",
    "                                   for home_goals in range(2)])\n",
    "    output_matrix[:2,:2] = output_matrix[:2,:2] * correction_matrix\n",
    "    return output_matrix\n",
    "\n",
    "full_time_matrices = []\n",
    "half_time_matrices = []\n",
    "\n",
    "for i in range(len(next_matches)):\n",
    "    my_league = next_matches['League'].iloc[i]\n",
    "    league_index = next_leagues.index(my_league)\n",
    "    ft_match_score_matrix = dixon_coles_simulate_match(full_time_models[league_index], \n",
    "                                                       next_matches['Home'].iloc[i], next_matches['Away'].iloc[i], max_goals = 8)\n",
    "    ht_match_score_matrix = dixon_coles_simulate_match(half_time_models[league_index], \n",
    "                                                       next_matches['Home'].iloc[i], next_matches['Away'].iloc[i], max_goals = 4)\n",
    "    full_time_matrices.append(ft_match_score_matrix)\n",
    "    half_time_matrices.append(ht_match_score_matrix)\n",
    "\n",
    "full_time_matrices[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Probabilities of Dixon-Coles Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_5ef6e_row0_col5, #T_5ef6e_row0_col8, #T_5ef6e_row0_col9, #T_5ef6e_row0_col10, #T_5ef6e_row0_col11, #T_5ef6e_row0_col21, #T_5ef6e_row0_col22, #T_5ef6e_row0_col25, #T_5ef6e_row0_col27, #T_5ef6e_row0_col28, #T_5ef6e_row1_col8, #T_5ef6e_row1_col12, #T_5ef6e_row1_col13, #T_5ef6e_row1_col28, #T_5ef6e_row1_col29, #T_5ef6e_row2_col13, #T_5ef6e_row2_col28, #T_5ef6e_row2_col29 {\n",
       "  background-color: red;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_5ef6e\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_5ef6e_level0_col0\" class=\"col_heading level0 col0\" >League</th>\n",
       "      <th id=\"T_5ef6e_level0_col1\" class=\"col_heading level0 col1\" >Home</th>\n",
       "      <th id=\"T_5ef6e_level0_col2\" class=\"col_heading level0 col2\" >Away</th>\n",
       "      <th id=\"T_5ef6e_level0_col3\" class=\"col_heading level0 col3\" >FT1</th>\n",
       "      <th id=\"T_5ef6e_level0_col4\" class=\"col_heading level0 col4\" >FTX</th>\n",
       "      <th id=\"T_5ef6e_level0_col5\" class=\"col_heading level0 col5\" >FT2</th>\n",
       "      <th id=\"T_5ef6e_level0_col6\" class=\"col_heading level0 col6\" >FTR</th>\n",
       "      <th id=\"T_5ef6e_level0_col7\" class=\"col_heading level0 col7\" >DC1X</th>\n",
       "      <th id=\"T_5ef6e_level0_col8\" class=\"col_heading level0 col8\" >DC12</th>\n",
       "      <th id=\"T_5ef6e_level0_col9\" class=\"col_heading level0 col9\" >DCX2</th>\n",
       "      <th id=\"T_5ef6e_level0_col10\" class=\"col_heading level0 col10\" >1.5O</th>\n",
       "      <th id=\"T_5ef6e_level0_col11\" class=\"col_heading level0 col11\" >2.5O</th>\n",
       "      <th id=\"T_5ef6e_level0_col12\" class=\"col_heading level0 col12\" >3.5U</th>\n",
       "      <th id=\"T_5ef6e_level0_col13\" class=\"col_heading level0 col13\" >4.5U</th>\n",
       "      <th id=\"T_5ef6e_level0_col14\" class=\"col_heading level0 col14\" >BTTS</th>\n",
       "      <th id=\"T_5ef6e_level0_col15\" class=\"col_heading level0 col15\" >HT1</th>\n",
       "      <th id=\"T_5ef6e_level0_col16\" class=\"col_heading level0 col16\" >HTX</th>\n",
       "      <th id=\"T_5ef6e_level0_col17\" class=\"col_heading level0 col17\" >HT2</th>\n",
       "      <th id=\"T_5ef6e_level0_col18\" class=\"col_heading level0 col18\" >HTR</th>\n",
       "      <th id=\"T_5ef6e_level0_col19\" class=\"col_heading level0 col19\" >HTDC1X</th>\n",
       "      <th id=\"T_5ef6e_level0_col20\" class=\"col_heading level0 col20\" >HTDC12</th>\n",
       "      <th id=\"T_5ef6e_level0_col21\" class=\"col_heading level0 col21\" >HTDCX2</th>\n",
       "      <th id=\"T_5ef6e_level0_col22\" class=\"col_heading level0 col22\" >HT0.5O</th>\n",
       "      <th id=\"T_5ef6e_level0_col23\" class=\"col_heading level0 col23\" >HT1.5U</th>\n",
       "      <th id=\"T_5ef6e_level0_col24\" class=\"col_heading level0 col24\" >H0.5O</th>\n",
       "      <th id=\"T_5ef6e_level0_col25\" class=\"col_heading level0 col25\" >A0.5O</th>\n",
       "      <th id=\"T_5ef6e_level0_col26\" class=\"col_heading level0 col26\" >H1.5O</th>\n",
       "      <th id=\"T_5ef6e_level0_col27\" class=\"col_heading level0 col27\" >A1.5O</th>\n",
       "      <th id=\"T_5ef6e_level0_col28\" class=\"col_heading level0 col28\" >H2.5U</th>\n",
       "      <th id=\"T_5ef6e_level0_col29\" class=\"col_heading level0 col29\" >A2.5U</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_5ef6e_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_5ef6e_row0_col0\" class=\"data row0 col0\" >Portugal2</td>\n",
       "      <td id=\"T_5ef6e_row0_col1\" class=\"data row0 col1\" >Portimonense</td>\n",
       "      <td id=\"T_5ef6e_row0_col2\" class=\"data row0 col2\" >Benfica B</td>\n",
       "      <td id=\"T_5ef6e_row0_col3\" class=\"data row0 col3\" >4.520000</td>\n",
       "      <td id=\"T_5ef6e_row0_col4\" class=\"data row0 col4\" >10.670000</td>\n",
       "      <td id=\"T_5ef6e_row0_col5\" class=\"data row0 col5\" >83.630000</td>\n",
       "      <td id=\"T_5ef6e_row0_col6\" class=\"data row0 col6\" >0-3</td>\n",
       "      <td id=\"T_5ef6e_row0_col7\" class=\"data row0 col7\" >15.190000</td>\n",
       "      <td id=\"T_5ef6e_row0_col8\" class=\"data row0 col8\" >88.150000</td>\n",
       "      <td id=\"T_5ef6e_row0_col9\" class=\"data row0 col9\" >94.300000</td>\n",
       "      <td id=\"T_5ef6e_row0_col10\" class=\"data row0 col10\" >93.670000</td>\n",
       "      <td id=\"T_5ef6e_row0_col11\" class=\"data row0 col11\" >81.680000</td>\n",
       "      <td id=\"T_5ef6e_row0_col12\" class=\"data row0 col12\" >33.900000</td>\n",
       "      <td id=\"T_5ef6e_row0_col13\" class=\"data row0 col13\" >52.840000</td>\n",
       "      <td id=\"T_5ef6e_row0_col14\" class=\"data row0 col14\" >58.330000</td>\n",
       "      <td id=\"T_5ef6e_row0_col15\" class=\"data row0 col15\" >4.580000</td>\n",
       "      <td id=\"T_5ef6e_row0_col16\" class=\"data row0 col16\" >15.560000</td>\n",
       "      <td id=\"T_5ef6e_row0_col17\" class=\"data row0 col17\" >74.780000</td>\n",
       "      <td id=\"T_5ef6e_row0_col18\" class=\"data row0 col18\" >0-1</td>\n",
       "      <td id=\"T_5ef6e_row0_col19\" class=\"data row0 col19\" >20.140000</td>\n",
       "      <td id=\"T_5ef6e_row0_col20\" class=\"data row0 col20\" >79.360000</td>\n",
       "      <td id=\"T_5ef6e_row0_col21\" class=\"data row0 col21\" >90.340000</td>\n",
       "      <td id=\"T_5ef6e_row0_col22\" class=\"data row0 col22\" >84.860000</td>\n",
       "      <td id=\"T_5ef6e_row0_col23\" class=\"data row0 col23\" >35.240000</td>\n",
       "      <td id=\"T_5ef6e_row0_col24\" class=\"data row0 col24\" >59.090000</td>\n",
       "      <td id=\"T_5ef6e_row0_col25\" class=\"data row0 col25\" >96.110000</td>\n",
       "      <td id=\"T_5ef6e_row0_col26\" class=\"data row0 col26\" >22.890000</td>\n",
       "      <td id=\"T_5ef6e_row0_col27\" class=\"data row0 col27\" >86.330000</td>\n",
       "      <td id=\"T_5ef6e_row0_col28\" class=\"data row0 col28\" >92.420000</td>\n",
       "      <td id=\"T_5ef6e_row0_col29\" class=\"data row0 col29\" >30.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ef6e_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_5ef6e_row1_col0\" class=\"data row1 col0\" >Spain2</td>\n",
       "      <td id=\"T_5ef6e_row1_col1\" class=\"data row1 col1\" >Sporting Gijon</td>\n",
       "      <td id=\"T_5ef6e_row1_col2\" class=\"data row1 col2\" >Castellon</td>\n",
       "      <td id=\"T_5ef6e_row1_col3\" class=\"data row1 col3\" >46.850000</td>\n",
       "      <td id=\"T_5ef6e_row1_col4\" class=\"data row1 col4\" >18.830000</td>\n",
       "      <td id=\"T_5ef6e_row1_col5\" class=\"data row1 col5\" >34.320000</td>\n",
       "      <td id=\"T_5ef6e_row1_col6\" class=\"data row1 col6\" >1-0</td>\n",
       "      <td id=\"T_5ef6e_row1_col7\" class=\"data row1 col7\" >65.680000</td>\n",
       "      <td id=\"T_5ef6e_row1_col8\" class=\"data row1 col8\" >81.170000</td>\n",
       "      <td id=\"T_5ef6e_row1_col9\" class=\"data row1 col9\" >53.150000</td>\n",
       "      <td id=\"T_5ef6e_row1_col10\" class=\"data row1 col10\" >59.960000</td>\n",
       "      <td id=\"T_5ef6e_row1_col11\" class=\"data row1 col11\" >38.120000</td>\n",
       "      <td id=\"T_5ef6e_row1_col12\" class=\"data row1 col12\" >81.640000</td>\n",
       "      <td id=\"T_5ef6e_row1_col13\" class=\"data row1 col13\" >92.590000</td>\n",
       "      <td id=\"T_5ef6e_row1_col14\" class=\"data row1 col14\" >39.370000</td>\n",
       "      <td id=\"T_5ef6e_row1_col15\" class=\"data row1 col15\" >34.650000</td>\n",
       "      <td id=\"T_5ef6e_row1_col16\" class=\"data row1 col16\" >32.740000</td>\n",
       "      <td id=\"T_5ef6e_row1_col17\" class=\"data row1 col17\" >32.540000</td>\n",
       "      <td id=\"T_5ef6e_row1_col18\" class=\"data row1 col18\" >0-0</td>\n",
       "      <td id=\"T_5ef6e_row1_col19\" class=\"data row1 col19\" >67.390000</td>\n",
       "      <td id=\"T_5ef6e_row1_col20\" class=\"data row1 col20\" >67.190000</td>\n",
       "      <td id=\"T_5ef6e_row1_col21\" class=\"data row1 col21\" >65.280000</td>\n",
       "      <td id=\"T_5ef6e_row1_col22\" class=\"data row1 col22\" >73.550000</td>\n",
       "      <td id=\"T_5ef6e_row1_col23\" class=\"data row1 col23\" >72.890000</td>\n",
       "      <td id=\"T_5ef6e_row1_col24\" class=\"data row1 col24\" >70.840000</td>\n",
       "      <td id=\"T_5ef6e_row1_col25\" class=\"data row1 col25\" >62.550000</td>\n",
       "      <td id=\"T_5ef6e_row1_col26\" class=\"data row1 col26\" >34.910000</td>\n",
       "      <td id=\"T_5ef6e_row1_col27\" class=\"data row1 col27\" >25.770000</td>\n",
       "      <td id=\"T_5ef6e_row1_col28\" class=\"data row1 col28\" >87.240000</td>\n",
       "      <td id=\"T_5ef6e_row1_col29\" class=\"data row1 col29\" >92.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_5ef6e_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_5ef6e_row2_col0\" class=\"data row2 col0\" >Usa</td>\n",
       "      <td id=\"T_5ef6e_row2_col1\" class=\"data row2 col1\" >Vancouver</td>\n",
       "      <td id=\"T_5ef6e_row2_col2\" class=\"data row2 col2\" >Los Angeles FC</td>\n",
       "      <td id=\"T_5ef6e_row2_col3\" class=\"data row2 col3\" >33.200000</td>\n",
       "      <td id=\"T_5ef6e_row2_col4\" class=\"data row2 col4\" >28.000000</td>\n",
       "      <td id=\"T_5ef6e_row2_col5\" class=\"data row2 col5\" >38.790000</td>\n",
       "      <td id=\"T_5ef6e_row2_col6\" class=\"data row2 col6\" >1-1</td>\n",
       "      <td id=\"T_5ef6e_row2_col7\" class=\"data row2 col7\" >61.200000</td>\n",
       "      <td id=\"T_5ef6e_row2_col8\" class=\"data row2 col8\" >71.990000</td>\n",
       "      <td id=\"T_5ef6e_row2_col9\" class=\"data row2 col9\" >66.790000</td>\n",
       "      <td id=\"T_5ef6e_row2_col10\" class=\"data row2 col10\" >79.630000</td>\n",
       "      <td id=\"T_5ef6e_row2_col11\" class=\"data row2 col11\" >54.710000</td>\n",
       "      <td id=\"T_5ef6e_row2_col12\" class=\"data row2 col12\" >67.620000</td>\n",
       "      <td id=\"T_5ef6e_row2_col13\" class=\"data row2 col13\" >83.650000</td>\n",
       "      <td id=\"T_5ef6e_row2_col14\" class=\"data row2 col14\" >59.530000</td>\n",
       "      <td id=\"T_5ef6e_row2_col15\" class=\"data row2 col15\" >26.210000</td>\n",
       "      <td id=\"T_5ef6e_row2_col16\" class=\"data row2 col16\" >34.900000</td>\n",
       "      <td id=\"T_5ef6e_row2_col17\" class=\"data row2 col17\" >38.670000</td>\n",
       "      <td id=\"T_5ef6e_row2_col18\" class=\"data row2 col18\" >0-0</td>\n",
       "      <td id=\"T_5ef6e_row2_col19\" class=\"data row2 col19\" >61.110000</td>\n",
       "      <td id=\"T_5ef6e_row2_col20\" class=\"data row2 col20\" >64.880000</td>\n",
       "      <td id=\"T_5ef6e_row2_col21\" class=\"data row2 col21\" >73.570000</td>\n",
       "      <td id=\"T_5ef6e_row2_col22\" class=\"data row2 col22\" >77.640000</td>\n",
       "      <td id=\"T_5ef6e_row2_col23\" class=\"data row2 col23\" >58.110000</td>\n",
       "      <td id=\"T_5ef6e_row2_col24\" class=\"data row2 col24\" >74.660000</td>\n",
       "      <td id=\"T_5ef6e_row2_col25\" class=\"data row2 col25\" >77.630000</td>\n",
       "      <td id=\"T_5ef6e_row2_col26\" class=\"data row2 col26\" >39.870000</td>\n",
       "      <td id=\"T_5ef6e_row2_col27\" class=\"data row2 col27\" >44.130000</td>\n",
       "      <td id=\"T_5ef6e_row2_col28\" class=\"data row2 col28\" >84.000000</td>\n",
       "      <td id=\"T_5ef6e_row2_col29\" class=\"data row2 col29\" >80.940000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x1b02ce8e600>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ft1, ftx, ft2, ft_score = [], [], [], []\n",
    "over_15, over_25, under_35, under_45, btts = [], [], [], [], []\n",
    "ht1, htx, ht2, ht_score, ht_over05, ht_under15 = [], [], [], [], [], []\n",
    "ho05, ao05, ho15, ao15, hu25, au25 = [], [], [], [], [], []\n",
    "\n",
    "# Helper function to calculate total goals for each score\n",
    "def total_goals(i, j):\n",
    "    return i + j\n",
    "\n",
    "for i in range(len(next_matches)):\n",
    "    my_matrix = full_time_matrices[i]\n",
    "    ht_matrix = half_time_matrices[i]\n",
    "\n",
    "    ft1.append(round(np.sum(np.tril(my_matrix, k=-1)) * 100, 2)) # Sum of lower triangular values (home win)\n",
    "    ftx.append(round(np.sum(np.diag(my_matrix)) * 100, 2)) # Sum of diagonal values (draw)\n",
    "    ft2.append(round(np.sum(np.triu(my_matrix, k=1)) * 100, 2)) # Sum of higher triangular values (away_win)\n",
    "    \n",
    "    max_score = np.unravel_index(np.argmax(my_matrix), my_matrix.shape) # Find the index of the maximum score\n",
    "    home_goals, away_goals = max_score\n",
    "    ft_score.append(f\"{home_goals}-{away_goals}\") # Format the score as 'home-away'\n",
    "\n",
    "    # Calculate the probabilities\n",
    "    over_15.append(round(np.sum([my_matrix[i, j] for i in range(my_matrix.shape[0]) for j in range(my_matrix.shape[1]) if total_goals(i, j) > 1.5]) * 100, 2))\n",
    "    over_25.append(round(np.sum([my_matrix[i, j] for i in range(my_matrix.shape[0]) for j in range(my_matrix.shape[1]) if total_goals(i, j) > 2.5]) * 100, 2))\n",
    "    under_35.append(round(np.sum([my_matrix[i, j] for i in range(my_matrix.shape[0]) for j in range(my_matrix.shape[1]) if total_goals(i, j) <= 3.5]) * 100, 2))\n",
    "    under_45.append(round(np.sum([my_matrix[i, j] for i in range(my_matrix.shape[0]) for j in range(my_matrix.shape[1]) if total_goals(i, j) <= 4.5]) * 100, 2))\n",
    "\n",
    "    # Calculate BTTS (both teams to score and goals != 0)\n",
    "    btts.append(round(np.sum([my_matrix[i, j] for i in range(1, my_matrix.shape[0]) for j in range(1, my_matrix.shape[1])]) * 100, 2)) \n",
    "\n",
    "    # Calculate statistics for Half Time\n",
    "    ht1.append(round(np.sum(np.tril(ht_matrix, k=-1)) * 100, 2)) # Sum of lower triangular values (home win)\n",
    "    htx.append(round(np.sum(np.diag(ht_matrix)) * 100, 2)) # Sum of diagonal values (draw)\n",
    "    ht2.append(round(np.sum(np.triu(ht_matrix, k=1)) * 100, 2)) # Sum of higher triangular values (away_win)\n",
    "\n",
    "    ht_max_score = np.unravel_index(np.argmax(ht_matrix), ht_matrix.shape) # Find the index of the maximum score\n",
    "    ht_hogs, ht_awgs = ht_max_score\n",
    "    ht_score.append(f\"{ht_hogs}-{ht_awgs}\") # Format the score as 'home-away'\n",
    "\n",
    "    ht_over05.append(round(np.sum([ht_matrix[i, j] for i in range(ht_matrix.shape[0]) for j in range(ht_matrix.shape[1]) if total_goals(i, j) > 0.5]) * 100, 2))   \n",
    "    ht_under15.append(round(np.sum([ht_matrix[i, j] for i in range(ht_matrix.shape[0]) for j in range(ht_matrix.shape[1]) if total_goals(i, j) < 1.5]) * 100, 2)) \n",
    "\n",
    "    ho05.append(round(np.sum(my_matrix[1:,:]) * 100, 2))\n",
    "    ao05.append(round(np.sum(my_matrix[:,1:]) * 100, 2))\n",
    "    ho15.append(round(np.sum(my_matrix[2:,:]) * 100, 2))\n",
    "    ao15.append(round(np.sum(my_matrix[:,2:]) * 100, 2))\n",
    "    hu25.append(round(np.sum(my_matrix[:3,:]) * 100, 2))\n",
    "    au25.append(round(np.sum(my_matrix[:,:3]) * 100, 2))\n",
    "    \n",
    "\n",
    "# Combine lists into a DataFrame\n",
    "final_results = pd.DataFrame({\n",
    "    'League': next_matches['League'], 'Home': next_matches['Home'], 'Away': next_matches['Away'],\n",
    "    'FT1': ft1, 'FTX': ftx, 'FT2': ft2, 'FTR': ft_score,\n",
    "    'DC1X': [x + y for x, y in zip(ft1, ftx)], 'DC12': [x + y for x, y in zip(ft1, ft2)], 'DCX2': [x + y for x, y in zip(ftx, ft2)],\n",
    "    '1.5O': over_15, '2.5O': over_25, '3.5U': under_35, '4.5U': under_45, 'BTTS': btts,\n",
    "    'HT1': ht1, 'HTX': htx, 'HT2': ht2, 'HTR': ht_score,\n",
    "    'HTDC1X': [x + y for x, y in zip(ht1, htx)], 'HTDC12': [x + y for x, y in zip(ht1, ht2)], 'HTDCX2': [x + y for x, y in zip(htx, ht2)],\n",
    "    'HT0.5O': ht_over05, 'HT1.5U': ht_under15, 'H0.5O':ho05, 'A0.5O':ao05, 'H1.5O':ho15, 'A1.5O':ao15, 'H2.5U':hu25, 'A2.5U':au25\n",
    "})\n",
    "\n",
    "# Function to highlight values higher than threshold\n",
    "def highlight_values(value):\n",
    "    if isinstance(value, str):\n",
    "        return ''  # Return empty string for NaN values\n",
    "    elif value > threshold:\n",
    "    #color = 'red'\n",
    "        return 'background-color: red'\n",
    "    else:\n",
    "        return ''\n",
    "\n",
    "# Apply the style\n",
    "with pd.option_context('display.precision', 2):\n",
    "    styled_df = final_results.style.applymap(highlight_values)\n",
    "styled_df.to_excel(given_date + \".xlsx\", index = False)\n",
    "# Display the styled DataFrame\n",
    "from IPython.display import display, HTML\n",
    "display(styled_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
